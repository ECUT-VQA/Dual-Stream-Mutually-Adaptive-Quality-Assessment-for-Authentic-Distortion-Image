<h1 align="center">Welcome to ECUT_VQA ğŸ‘‹</h1>
<p>
  <img alt="Version" src="https://img.shields.io/badge/version-1.0-blue.svg?cacheSeconds=2592000" />
</p>

Welcome to ECUT_VQA (Visual Quality Assessment group of East China University of Technology)

<div align="center">
    <b><a href="#ä¸­æ–‡è¯´æ˜">ä¸­æ–‡</a> | <a href="#english-description">English</a></b>
</div>

This is the PyTorch implementation of our paper accepted to Journal of Visual Communication and Image Representation. Thank you for your citation (Dual-stream mutually adaptive quality assessment for authentic 
distortion image. J. Vis. Commun. Image R. 102 (2024) 104216. [https: //doi. org/10.1016/j.jvcir.2024.104216].

<!-- ä¸­æ–‡å†…å®¹ -->
## <a name="ä¸­æ–‡è¯´æ˜"></a>ä¸­æ–‡è¯´æ˜
> å±•ç¤ºè¯¾é¢˜ç»„è®ºæ–‡æˆæœ

åŸºäºpytorchå¼€å‘çš„æ— å‚è€ƒå›¾åƒè´¨é‡è¯„ä»·ç®—æ³•ã€‚è¯„ä»·æ•ˆæœå›¾è¯·[ç‚¹å‡»è¿™é‡Œ](#æ•ˆæœå›¾)æŸ¥çœ‹ã€‚  


## ç›®å½•

1. [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
2. [å¼€å‘æŒ‡å—](#å¼€å‘æŒ‡å—)
3. [æ•ˆæœå›¾](#æ•ˆæœå›¾)

## ç¯å¢ƒé…ç½®

1. é¦–å…ˆç¡®ä¿å·²ç»å®‰è£…å’Œé…ç½®å¥½çš„pythonç‰ˆæœ¬>=3.8
2. pytorch>=1.13.1ã€
3. cuda>=11.7
4. cudnn>=8.0 
5. ä»ä»“åº“ä¸‹è½½requements.txt,å¹¶æ ¹æ®è¿™ä¸ªç¯å¢ƒä¸‹è½½æ‰€æœ‰éœ€è¦çš„åŒ…
6. æ ¹æ®æç¤ºï¼Œä¸‹è½½ä»£ç ï¼Œè®­ç»ƒè‡ªå·±çš„æ¨¡å‹ï¼Œæˆ–è€…åŠ è½½æˆ‘ä»¬æä¾›çš„æ¨¡å‹å‚æ•°


## å¼€å‘æŒ‡å—
1. ä¸‹è½½å¯¹åº”çš„å…¬å¼€æ•°æ®é›†å’Œæ ‡ç­¾æ–‡ä»¶
2. é¦–å…ˆè®­ç»ƒè‡ªå·±çš„åŒæµç½‘ç»œæˆ–è€…æå–è‡ªå·±çš„åŒæµç‰¹å¾
3. æ ¹æ®æˆ‘ä»¬çš„å®éªŒï¼Œå¯ä»¥ç”¨äºåŸºäºå¯¹æ¯”å­¦ä¹ å’ŒåŸºäºvaeçš„å›¾åƒè´¨é‡è¯„ä»·ç®—æ³•ä¸­


## æ•ˆæœå›¾
![](./image/è®ºæ–‡.png)
![](./image/æ·»åŠ .png)
![](./image/ç®¡ç†.png)

<!-- è‹±æ–‡å†…å®¹ -->
## <a name="english-description"></a>English Description
>Display our research team's paper achievements

  A no-reference  image quality assessment algorithm developed based on PyTorch. Please [click here] (#æ•ˆæœå›¾) to view the evaluation rendering.
1. [Environment Configuration] (# Environment Configuration)
2. [Development Guide] (# Development Guide)
3. [Renderings] (# Renderings)

## Environment Configuration
1. First, ensure that the installed and configured Python version is>=3.8
2. pytorch>=1.13.1
3. cuda>=11.7
4. cudnn>=8.0
5. Download requests.txt from the repository and download all required packages according to this environment
6. According to the prompts, download the code, train your own model, or load the model parameters we provide

## Development Guide
1. Download the corresponding public dataset and label files
2. First, train your own dual-stream network or extract your own dual-stream features
3. According to our experiment, it can be used in image quality assessment algorithms based on contrastive learning and VAE

## Renderings

## Author

ğŸ‘¤ **ECUT_VQA**

## Show your support
For more details, please wait for further organization of the code

Give a â­ï¸ if this project helped you and quote our paper!
